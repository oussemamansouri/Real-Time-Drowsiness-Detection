{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Video Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import winsound\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model And Defining Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('models/Eye_Model1.h5')\n",
    "class_names = ['Close-Eyes', 'Open-Eyes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set sound frequency and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 2500  # Hz\n",
    "duration = 2000   # 2 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MediaPipe face mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open webcam For A Real-Time Video Demo\n",
    "- The code captures video from the webcam.\n",
    "- Detects faces and eyes using OpenCV.\n",
    "- Uses a deep learning model to classify eye state.\n",
    "- Alerts the user if no face is detected for 3 seconds.\n",
    "- Triggers a sleep alert if eyes are closed for too long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot Open Webcam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "status = \"Open Eyes\"\n",
    "face_detected_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Eye landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_EYE_LANDMARKS = [33, 133, 153, 154, 155, 133]\n",
    "RIGHT_EYE_LANDMARKS = [263, 362, 387, 386, 385, 362]\n",
    "padding = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eye_box(landmarks, landmark_indices, frame_shape):\n",
    "    points = [(int(landmarks.landmark[i].x * frame_shape[1]),\n",
    "               int(landmarks.landmark[i].y * frame_shape[0])) for i in landmark_indices]\n",
    "    x_min = min(p[0] for p in points) - padding\n",
    "    y_min = min(p[1] for p in points) - padding\n",
    "    x_max = max(p[0] for p in points) + padding\n",
    "    y_max = max(p[1] for p in points) + padding\n",
    "    return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "def predict_eye_state(eye):\n",
    "    if eye.size == 0: return 'Close-Eyes', 0.0\n",
    "    eye_resized = cv2.resize(eye, (256, 256)) / 255.0\n",
    "    eye_input = np.expand_dims(eye_resized, axis=0)\n",
    "    prediction = model.predict(eye_input)\n",
    "    return class_names[np.argmax(prediction[0])], np.max(prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks is None:\n",
    "        if time.time() - face_detected_time > 3:\n",
    "            cv2.putText(frame, 'Face Missing Alert!', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            winsound.Beep(frequency, duration)\n",
    "    else:\n",
    "        face_detected_time = time.time()\n",
    "        for landmarks in results.multi_face_landmarks:\n",
    "            left_x1, left_y1, left_x2, left_y2 = get_eye_box(landmarks, LEFT_EYE_LANDMARKS, frame.shape)\n",
    "            right_x1, right_y1, right_x2, right_y2 = get_eye_box(landmarks, RIGHT_EYE_LANDMARKS, frame.shape)\n",
    "\n",
    "            left_eye = frame[left_y1:left_y2, left_x1:left_x2]\n",
    "            right_eye = frame[right_y1:right_y2, right_x1:right_x2]\n",
    "\n",
    "            left_eye_status, _ = predict_eye_state(left_eye)\n",
    "            right_eye_status, _ = predict_eye_state(right_eye)\n",
    "\n",
    "            left_color = (0, 0, 255) if left_eye_status == 'Close-Eyes' else (0, 255, 0)\n",
    "            right_color = (0, 0, 255) if right_eye_status == 'Close-Eyes' else (0, 255, 0)\n",
    "\n",
    "            cv2.rectangle(frame, (left_x1, left_y1), (left_x2, left_y2), left_color, 2)\n",
    "            cv2.rectangle(frame, (right_x1, right_y1), (right_x2, right_y2), right_color, 2)\n",
    "\n",
    "            if left_eye_status == 'Close-Eyes' and right_eye_status == 'Close-Eyes':\n",
    "                counter += 1\n",
    "                status = \"Closed Eyes\"\n",
    "            else:\n",
    "                counter = 0\n",
    "                status = \"Open Eyes\"\n",
    "\n",
    "            cv2.putText(frame, status, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "            if counter > 5:\n",
    "                cv2.putText(frame, 'Sleep Alert !!', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                winsound.Beep(frequency, duration)\n",
    "                counter = 0\n",
    "\n",
    "    cv2.imshow(\"Real-Time Eye Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import winsound\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialiser MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)\n",
    "\n",
    "# Charger le modèle entraîné\n",
    "new_model = tf.keras.models.load_model('models/Eye_Model1.h5', compile=False)\n",
    "new_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Paramètres globaux\n",
    "LEFT_EYE_LANDMARKS = [33, 133, 153, 154, 155, 133]\n",
    "RIGHT_EYE_LANDMARKS = [263, 362, 387, 386, 385, 362]\n",
    "class_names = ['Close-Eyes', 'Open-Eyes']\n",
    "padding = 20\n",
    "frequency = 2500\n",
    "duration = 2000\n",
    "\n",
    "def get_eye_box(landmarks, indices, frame_shape):\n",
    "    points = [\n",
    "        (int(landmarks.landmark[i].x * frame_shape[1]),  # x\n",
    "         int(landmarks.landmark[i].y * frame_shape[0]))  # y\n",
    "        for i in indices\n",
    "    ]\n",
    "    \n",
    "    x_min = max(0, min(p[0] for p in points) - padding)\n",
    "    y_min = max(0, min(p[1] for p in points) - padding)\n",
    "    x_max = min(frame_shape[1], max(p[0] for p in points) + padding)\n",
    "    y_max = min(frame_shape[0], max(p[1] for p in points) + padding)\n",
    "    \n",
    "    return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "def predict_eye_state(eye):\n",
    "    if eye.size == 0:\n",
    "        return 'Close-Eyes', 0.0\n",
    "\n",
    "    # ✅ Redimensionner à la taille attendue par le modèle\n",
    "    eye_resized = cv2.resize(eye, (256, 256))\n",
    "    eye_normalized = eye_resized / 255.0\n",
    "    eye_input = np.expand_dims(eye_normalized, axis=0)\n",
    "\n",
    "    prediction = new_model.predict(eye_input, verbose=0)\n",
    "    return class_names[np.argmax(prediction[0])], np.max(prediction[0])\n",
    "\n",
    "# Capture vidéo\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for landmarks in results.multi_face_landmarks:\n",
    "            left_box = get_eye_box(landmarks, LEFT_EYE_LANDMARKS, frame.shape)\n",
    "            right_box = get_eye_box(landmarks, RIGHT_EYE_LANDMARKS, frame.shape)\n",
    "\n",
    "            left_eye = frame[left_box[1]:left_box[3], left_box[0]:left_box[2]]\n",
    "            right_eye = frame[right_box[1]:right_box[3], right_box[0]:right_box[2]]\n",
    "\n",
    "            # Prédiction\n",
    "            left_status, left_conf = predict_eye_state(left_eye)\n",
    "            right_status, right_conf = predict_eye_state(right_eye)\n",
    "\n",
    "            # Logique d'alerte\n",
    "            if left_status == 'Close-Eyes' and right_status == 'Close-Eyes':\n",
    "                cv2.putText(frame, 'ALERTE: Yeux fermes!', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                winsound.Beep(frequency, duration)\n",
    "\n",
    "            # Affichage des résultats\n",
    "            cv2.putText(frame, f'Gauche: {left_status} ({left_conf:.2f})', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f'Droite: {right_status} ({right_conf:.2f})', (50, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "            # Dessiner les rectangles des yeux\n",
    "            cv2.rectangle(frame, (left_box[0], left_box[1]), (left_box[2], left_box[3]), (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (right_box[0], right_box[1]), (right_box[2], right_box[3]), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Eye State Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
