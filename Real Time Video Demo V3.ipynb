{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Video Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import winsound\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model And Defining Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('models/Eye_Model2.h5')\n",
    "class_names = ['Close-Eyes', 'Open-Eyes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set sound frequency and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 2500  # Hz\n",
    "duration = 2000   # 2 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MediaPipe face mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open webcam For A Real-Time Video Demo\n",
    "- The code captures video from the webcam.\n",
    "- Detects faces and eyes using OpenCV.\n",
    "- Uses a deep learning model to classify eye state.\n",
    "- Alerts the user if no face is detected for 3 seconds.\n",
    "- Triggers a sleep alert if eyes are closed for too long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot Open Webcam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "status = \"Open Eyes\"\n",
    "face_detected_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Eye landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_EYE_LANDMARKS = [33, 133, 153, 154, 155, 133]\n",
    "RIGHT_EYE_LANDMARKS = [263, 362, 387, 386, 385, 362]\n",
    "padding = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eye_box(landmarks, landmark_indices, frame_shape):\n",
    "    points = [(int(landmarks.landmark[i].x * frame_shape[1]),\n",
    "               int(landmarks.landmark[i].y * frame_shape[0])) for i in landmark_indices]\n",
    "    x_min = min(p[0] for p in points) - padding\n",
    "    y_min = min(p[1] for p in points) - padding\n",
    "    x_max = max(p[0] for p in points) + padding\n",
    "    y_max = max(p[1] for p in points) + padding\n",
    "    return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "def predict_eye_state(eye):\n",
    "    if eye.size == 0: return 'Close-Eyes', 0.0\n",
    "    eye_resized = cv2.resize(eye, (256, 256)) / 255.0\n",
    "    eye_input = np.expand_dims(eye_resized, axis=0)\n",
    "    prediction = model.predict(eye_input)\n",
    "    return class_names[np.argmax(prediction[0])], np.max(prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks is None:\n",
    "        if time.time() - face_detected_time > 3:\n",
    "            cv2.putText(frame, 'Face Missing Alert!', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            winsound.Beep(frequency, duration)\n",
    "    else:\n",
    "        face_detected_time = time.time()\n",
    "        for landmarks in results.multi_face_landmarks:\n",
    "            left_x1, left_y1, left_x2, left_y2 = get_eye_box(landmarks, LEFT_EYE_LANDMARKS, frame.shape)\n",
    "            right_x1, right_y1, right_x2, right_y2 = get_eye_box(landmarks, RIGHT_EYE_LANDMARKS, frame.shape)\n",
    "\n",
    "            left_eye = frame[left_y1:left_y2, left_x1:left_x2]\n",
    "            right_eye = frame[right_y1:right_y2, right_x1:right_x2]\n",
    "\n",
    "            left_eye_status, _ = predict_eye_state(left_eye)\n",
    "            right_eye_status, _ = predict_eye_state(right_eye)\n",
    "\n",
    "            left_color = (0, 0, 255) if left_eye_status == 'Close-Eyes' else (0, 255, 0)\n",
    "            right_color = (0, 0, 255) if right_eye_status == 'Close-Eyes' else (0, 255, 0)\n",
    "\n",
    "            cv2.rectangle(frame, (left_x1, left_y1), (left_x2, left_y2), left_color, 2)\n",
    "            cv2.rectangle(frame, (right_x1, right_y1), (right_x2, right_y2), right_color, 2)\n",
    "\n",
    "            if left_eye_status == 'Close-Eyes' and right_eye_status == 'Close-Eyes':\n",
    "                counter += 1\n",
    "                status = \"Closed Eyes\"\n",
    "            else:\n",
    "                counter = 0\n",
    "                status = \"Open Eyes\"\n",
    "\n",
    "            cv2.putText(frame, status, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "            if counter > 5:\n",
    "                cv2.putText(frame, 'Sleep Alert !!', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                winsound.Beep(frequency, duration)\n",
    "                counter = 0\n",
    "\n",
    "    cv2.imshow(\"Real-Time Eye Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# import mediapipe as mp\n",
    "\n",
    "# # Load the model\n",
    "# new_model = tf.keras.models.load_model('models/Eye_Model2.h5')\n",
    "# class_names = ['Close-Eyes', 'Open-Eyes']\n",
    "\n",
    "# # Read the image\n",
    "# img = cv2.imread(\"close.jpg\")\n",
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# # Initialize MediaPipe Face Mesh\n",
    "# mp_face_mesh = mp.solutions.face_mesh\n",
    "# face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "# # Convert the image to RGB\n",
    "# img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # Process the image to detect faces and facial landmarks\n",
    "# results = face_mesh.process(img_rgb)\n",
    "\n",
    "# # Check if landmarks were detected\n",
    "# if results.multi_face_landmarks:\n",
    "#     for face_landmarks in results.multi_face_landmarks:\n",
    "#         # Get landmarks for both eyes (right eye and left eye)\n",
    "#         left_eye_landmarks = [33, 133, 153, 154, 155, 133]\n",
    "#         right_eye_landmarks = [263, 362, 387, 386, 385, 362]\n",
    "\n",
    "#         # Initialize min and max values for the bounding box\n",
    "#         left_eye_x_min, left_eye_y_min = float('inf'), float('inf')\n",
    "#         left_eye_x_max, left_eye_y_max = -float('inf'), -float('inf')\n",
    "\n",
    "#         right_eye_x_min, right_eye_y_min = float('inf'), float('inf')\n",
    "#         right_eye_x_max, right_eye_y_max = -float('inf'), -float('inf')\n",
    "\n",
    "#         # Get the pixel coordinates for the left eye landmarks\n",
    "#         h, w, _ = img.shape\n",
    "#         for idx in left_eye_landmarks:\n",
    "#             x, y = int(face_landmarks.landmark[idx].x * w), int(face_landmarks.landmark[idx].y * h)\n",
    "#             left_eye_x_min = min(left_eye_x_min, x)\n",
    "#             left_eye_y_min = min(left_eye_y_min, y)\n",
    "#             left_eye_x_max = max(left_eye_x_max, x)\n",
    "#             left_eye_y_max = max(left_eye_y_max, y)\n",
    "\n",
    "#         # Get the pixel coordinates for the right eye landmarks\n",
    "#         for idx in right_eye_landmarks:\n",
    "#             x, y = int(face_landmarks.landmark[idx].x * w), int(face_landmarks.landmark[idx].y * h)\n",
    "#             right_eye_x_min = min(right_eye_x_min, x)\n",
    "#             right_eye_y_min = min(right_eye_y_min, y)\n",
    "#             right_eye_x_max = max(right_eye_x_max, x)\n",
    "#             right_eye_y_max = max(right_eye_y_max, y)\n",
    "\n",
    "#         # Apply padding to the bounding boxes to extend their width and height\n",
    "#         padding = 16  # Add padding to the bounding box for better coverage\n",
    "#         left_eye_x_min -= padding\n",
    "#         left_eye_y_min -= padding\n",
    "#         left_eye_x_max += padding\n",
    "#         left_eye_y_max += padding\n",
    "\n",
    "#         right_eye_x_min -= padding\n",
    "#         right_eye_y_min -= padding\n",
    "#         right_eye_x_max += padding\n",
    "#         right_eye_y_max += padding\n",
    "\n",
    "#         # Draw bounding boxes around the eyes using the adjusted coordinates\n",
    "#         cv2.rectangle(img, (left_eye_x_min, left_eye_y_min), (left_eye_x_max, left_eye_y_max), (0, 255, 0), 2)\n",
    "#         cv2.rectangle(img, (right_eye_x_min, right_eye_y_min), (right_eye_x_max, right_eye_y_max), (0, 255, 0), 2)\n",
    "\n",
    "#         # Crop the eye regions for further prediction\n",
    "#         left_eye_roi = img[left_eye_y_min:left_eye_y_max, left_eye_x_min:left_eye_x_max]\n",
    "#         right_eye_roi = img[right_eye_y_min:right_eye_y_max, right_eye_x_min:right_eye_x_max]\n",
    "\n",
    "#         # Show the image with rectangles drawn\n",
    "#         plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#         plt.show()\n",
    "\n",
    "#         # Preprocess the eye regions for model prediction\n",
    "#         IMAGE_SIZE = 256\n",
    "\n",
    "#         # Resize and preprocess the left eye image\n",
    "#         left_eye_final = cv2.resize(left_eye_roi, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "#         left_eye_final = np.expand_dims(left_eye_final, axis=0)  # Add batch dimension\n",
    "#         left_eye_final = left_eye_final / 255.0  # Normalize\n",
    "\n",
    "#         # Resize and preprocess the right eye image\n",
    "#         right_eye_final = cv2.resize(right_eye_roi, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "#         right_eye_final = np.expand_dims(right_eye_final, axis=0)  # Add batch dimension\n",
    "#         right_eye_final = right_eye_final / 255.0  # Normalize\n",
    "\n",
    "#         # Make the prediction for the left eye\n",
    "#         left_eye_predictions = new_model.predict(left_eye_final)\n",
    "#         left_eye_predicted_class = class_names[np.argmax(left_eye_predictions[0])]\n",
    "#         left_eye_confidence = round(100 * (np.max(left_eye_predictions[0])), 2)\n",
    "#         print(f\"Left Eye Predicted: {left_eye_predicted_class}.\\nConfidence: {left_eye_confidence}%\")\n",
    "\n",
    "#         # Make the prediction for the right eye\n",
    "#         right_eye_predictions = new_model.predict(right_eye_final)\n",
    "#         right_eye_predicted_class = class_names[np.argmax(right_eye_predictions[0])]\n",
    "#         right_eye_confidence = round(100 * (np.max(right_eye_predictions[0])), 2)\n",
    "#         print(f\"Right Eye Predicted: {right_eye_predicted_class}.\\nConfidence: {right_eye_confidence}%\")\n",
    "\n",
    "# else:\n",
    "#     print(\"No faces detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import winsound\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "# YOLO Model setup\n",
    "yolo_net = cv2.dnn.readNet('yolov4.weights', 'yolov4.cfg')\n",
    "layers_names = yolo_net.getLayerNames()\n",
    "out_layers = [layers_names[i[0] - 1] for i in yolo_net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Parameters\n",
    "frequency = 2500\n",
    "duration = 500\n",
    "face_detected_time = time.time()\n",
    "counter = 0\n",
    "\n",
    "# Functions\n",
    "def get_eye_box(landmarks, eye_landmarks, frame_shape):\n",
    "    h, w, _ = frame_shape\n",
    "    x_coords = [int(landmarks.landmark[i].x * w) for i in eye_landmarks]\n",
    "    y_coords = [int(landmarks.landmark[i].y * h) for i in eye_landmarks]\n",
    "    return min(x_coords), min(y_coords), max(x_coords), max(y_coords)\n",
    "\n",
    "def predict_eye_state(eye_image):\n",
    "    gray_eye = cv2.cvtColor(eye_image, cv2.COLOR_BGR2GRAY)\n",
    "    resized_eye = cv2.resize(gray_eye, (24, 24))\n",
    "    normalized_eye = resized_eye / 255.0\n",
    "    return (\"Close-Eyes\", 1.0) if np.mean(normalized_eye) < 0.5 else (\"Open-Eyes\", 0.0)\n",
    "\n",
    "# Eye Landmarks for MediaPipe\n",
    "LEFT_EYE_LANDMARKS = [362, 385, 387, 263, 373, 380]\n",
    "RIGHT_EYE_LANDMARKS = [33, 160, 158, 133, 153, 144]\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    # YOLO detection\n",
    "    height, width, channels = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    yolo_net.setInput(blob)\n",
    "    outputs = yolo_net.forward(out_layers)\n",
    "\n",
    "    face_detected = False\n",
    "    yolo_drowsy = False\n",
    "\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and class_id == 0:  # Assuming 0 is 'person'\n",
    "                x_center, y_center, w, h = (detection[0:4] * np.array([width, height, width, height])).astype('int')\n",
    "                x1, y1 = int(x_center - w / 2), int(y_center - h / 2)\n",
    "                x2, y2 = int(x_center + w / 2), int(y_center + h / 2)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                face_detected = True\n",
    "                if class_id == 0 and confidence > 0.6:\n",
    "                    yolo_drowsy = True\n",
    "\n",
    "    if results.multi_face_landmarks is None:\n",
    "        if time.time() - face_detected_time > 3:\n",
    "            cv2.putText(frame, 'Face Missing Alert!', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            winsound.Beep(frequency, duration)\n",
    "    else:\n",
    "        face_detected_time = time.time()\n",
    "        for landmarks in results.multi_face_landmarks:\n",
    "            left_x1, left_y1, left_x2, left_y2 = get_eye_box(landmarks, LEFT_EYE_LANDMARKS, frame.shape)\n",
    "            right_x1, right_y1, right_x2, right_y2 = get_eye_box(landmarks, RIGHT_EYE_LANDMARKS, frame.shape)\n",
    "\n",
    "            left_eye = frame[left_y1:left_y2, left_x1:left_x2]\n",
    "            right_eye = frame[right_y1:right_y2, right_x1:right_x2]\n",
    "\n",
    "            left_eye_status, _ = predict_eye_state(left_eye)\n",
    "            right_eye_status, _ = predict_eye_state(right_eye)\n",
    "\n",
    "            left_color = (0, 0, 255) if left_eye_status == 'Close-Eyes' else (0, 255, 0)\n",
    "            right_color = (0, 0, 255) if right_eye_status == 'Close-Eyes' else (0, 255, 0)\n",
    "\n",
    "            cv2.rectangle(frame, (left_x1, left_y1), (left_x2, left_y2), left_color, 2)\n",
    "            cv2.rectangle(frame, (right_x1, right_y1), (right_x2, right_y2), right_color, 2)\n",
    "\n",
    "            if left_eye_status == 'Close-Eyes' and right_eye_status == 'Close-Eyes' and yolo_drowsy:\n",
    "                counter += 1\n",
    "                status = \"Drowsy\"\n",
    "            else:\n",
    "                counter = 0\n",
    "                status = \"Not Drowsy\"\n",
    "\n",
    "            cv2.putText(frame, status, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "            if counter > 5:\n",
    "                cv2.putText(frame, 'Sleep Alert !!', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                winsound.Beep(frequency, duration)\n",
    "                counter = 0\n",
    "\n",
    "    cv2.imshow(\"Real-Time Eye Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
