{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Video Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import winsound\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model And Defining Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('models/Eye_Model2.h5')\n",
    "class_names = ['Close-Eyes', 'Open-Eyes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set sound frequency and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = 2500  # Hz\n",
    "duration = 2000   # 2 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MediaPipe face mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open webcam For A Real-Time Video Demo\n",
    "- The code captures video from the webcam.\n",
    "- Detects faces and eyes using OpenCV.\n",
    "- Uses a deep learning model to classify eye state.\n",
    "- Alerts the user if no face is detected for 3 seconds.\n",
    "- Triggers a sleep alert if eyes are closed for too long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot Open Webcam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "status = \"Open Eyes\"\n",
    "face_detected_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Eye landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_EYE_LANDMARKS = [33, 133, 153, 154, 155, 133]\n",
    "RIGHT_EYE_LANDMARKS = [263, 362, 387, 386, 385, 362]\n",
    "padding = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eye_box(landmarks, landmark_indices, frame_shape):\n",
    "    points = [(int(landmarks.landmark[i].x * frame_shape[1]),\n",
    "               int(landmarks.landmark[i].y * frame_shape[0])) for i in landmark_indices]\n",
    "    x_min = min(p[0] for p in points) - padding\n",
    "    y_min = min(p[1] for p in points) - padding\n",
    "    x_max = max(p[0] for p in points) + padding\n",
    "    y_max = max(p[1] for p in points) + padding\n",
    "    return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "def predict_eye_state(eye):\n",
    "    if eye.size == 0: return 'Close-Eyes', 0.0\n",
    "    eye_resized = cv2.resize(eye, (256, 256)) / 255.0\n",
    "    eye_input = np.expand_dims(eye_resized, axis=0)\n",
    "    prediction = model.predict(eye_input)\n",
    "    return class_names[np.argmax(prediction[0])], np.max(prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks is None:\n",
    "        if time.time() - face_detected_time > 3:\n",
    "            cv2.putText(frame, 'Face Missing Alert!', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            winsound.Beep(frequency, duration)\n",
    "    else:\n",
    "        face_detected_time = time.time()\n",
    "        for landmarks in results.multi_face_landmarks:\n",
    "            left_x1, left_y1, left_x2, left_y2 = get_eye_box(landmarks, LEFT_EYE_LANDMARKS, frame.shape)\n",
    "            right_x1, right_y1, right_x2, right_y2 = get_eye_box(landmarks, RIGHT_EYE_LANDMARKS, frame.shape)\n",
    "\n",
    "            left_eye = frame[left_y1:left_y2, left_x1:left_x2]\n",
    "            right_eye = frame[right_y1:right_y2, right_x1:right_x2]\n",
    "\n",
    "            left_eye_status, _ = predict_eye_state(left_eye)\n",
    "            right_eye_status, _ = predict_eye_state(right_eye)\n",
    "\n",
    "            left_color = (0, 0, 255) if left_eye_status == 'Close-Eyes' else (0, 255, 0)\n",
    "            right_color = (0, 0, 255) if right_eye_status == 'Close-Eyes' else (0, 255, 0)\n",
    "\n",
    "            cv2.rectangle(frame, (left_x1, left_y1), (left_x2, left_y2), left_color, 2)\n",
    "            cv2.rectangle(frame, (right_x1, right_y1), (right_x2, right_y2), right_color, 2)\n",
    "\n",
    "            if left_eye_status == 'Close-Eyes' and right_eye_status == 'Close-Eyes':\n",
    "                counter += 1\n",
    "                status = \"Closed Eyes\"\n",
    "            else:\n",
    "                counter = 0\n",
    "                status = \"Open Eyes\"\n",
    "\n",
    "            cv2.putText(frame, status, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "            if counter > 5:\n",
    "                cv2.putText(frame, 'Sleep Alert !!', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                winsound.Beep(frequency, duration)\n",
    "                counter = 0\n",
    "\n",
    "    cv2.imshow(\"Real-Time Eye Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# import mediapipe as mp\n",
    "\n",
    "# # Load the model\n",
    "# new_model = tf.keras.models.load_model('models/Eye_Model2.h5')\n",
    "# class_names = ['Close-Eyes', 'Open-Eyes']\n",
    "\n",
    "# # Read the image\n",
    "# img = cv2.imread(\"close.jpg\")\n",
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# # Initialize MediaPipe Face Mesh\n",
    "# mp_face_mesh = mp.solutions.face_mesh\n",
    "# face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "# # Convert the image to RGB\n",
    "# img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # Process the image to detect faces and facial landmarks\n",
    "# results = face_mesh.process(img_rgb)\n",
    "\n",
    "# # Check if landmarks were detected\n",
    "# if results.multi_face_landmarks:\n",
    "#     for face_landmarks in results.multi_face_landmarks:\n",
    "#         # Get landmarks for both eyes (right eye and left eye)\n",
    "#         left_eye_landmarks = [33, 133, 153, 154, 155, 133]\n",
    "#         right_eye_landmarks = [263, 362, 387, 386, 385, 362]\n",
    "\n",
    "#         # Initialize min and max values for the bounding box\n",
    "#         left_eye_x_min, left_eye_y_min = float('inf'), float('inf')\n",
    "#         left_eye_x_max, left_eye_y_max = -float('inf'), -float('inf')\n",
    "\n",
    "#         right_eye_x_min, right_eye_y_min = float('inf'), float('inf')\n",
    "#         right_eye_x_max, right_eye_y_max = -float('inf'), -float('inf')\n",
    "\n",
    "#         # Get the pixel coordinates for the left eye landmarks\n",
    "#         h, w, _ = img.shape\n",
    "#         for idx in left_eye_landmarks:\n",
    "#             x, y = int(face_landmarks.landmark[idx].x * w), int(face_landmarks.landmark[idx].y * h)\n",
    "#             left_eye_x_min = min(left_eye_x_min, x)\n",
    "#             left_eye_y_min = min(left_eye_y_min, y)\n",
    "#             left_eye_x_max = max(left_eye_x_max, x)\n",
    "#             left_eye_y_max = max(left_eye_y_max, y)\n",
    "\n",
    "#         # Get the pixel coordinates for the right eye landmarks\n",
    "#         for idx in right_eye_landmarks:\n",
    "#             x, y = int(face_landmarks.landmark[idx].x * w), int(face_landmarks.landmark[idx].y * h)\n",
    "#             right_eye_x_min = min(right_eye_x_min, x)\n",
    "#             right_eye_y_min = min(right_eye_y_min, y)\n",
    "#             right_eye_x_max = max(right_eye_x_max, x)\n",
    "#             right_eye_y_max = max(right_eye_y_max, y)\n",
    "\n",
    "#         # Apply padding to the bounding boxes to extend their width and height\n",
    "#         padding = 16  # Add padding to the bounding box for better coverage\n",
    "#         left_eye_x_min -= padding\n",
    "#         left_eye_y_min -= padding\n",
    "#         left_eye_x_max += padding\n",
    "#         left_eye_y_max += padding\n",
    "\n",
    "#         right_eye_x_min -= padding\n",
    "#         right_eye_y_min -= padding\n",
    "#         right_eye_x_max += padding\n",
    "#         right_eye_y_max += padding\n",
    "\n",
    "#         # Draw bounding boxes around the eyes using the adjusted coordinates\n",
    "#         cv2.rectangle(img, (left_eye_x_min, left_eye_y_min), (left_eye_x_max, left_eye_y_max), (0, 255, 0), 2)\n",
    "#         cv2.rectangle(img, (right_eye_x_min, right_eye_y_min), (right_eye_x_max, right_eye_y_max), (0, 255, 0), 2)\n",
    "\n",
    "#         # Crop the eye regions for further prediction\n",
    "#         left_eye_roi = img[left_eye_y_min:left_eye_y_max, left_eye_x_min:left_eye_x_max]\n",
    "#         right_eye_roi = img[right_eye_y_min:right_eye_y_max, right_eye_x_min:right_eye_x_max]\n",
    "\n",
    "#         # Show the image with rectangles drawn\n",
    "#         plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#         plt.show()\n",
    "\n",
    "#         # Preprocess the eye regions for model prediction\n",
    "#         IMAGE_SIZE = 256\n",
    "\n",
    "#         # Resize and preprocess the left eye image\n",
    "#         left_eye_final = cv2.resize(left_eye_roi, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "#         left_eye_final = np.expand_dims(left_eye_final, axis=0)  # Add batch dimension\n",
    "#         left_eye_final = left_eye_final / 255.0  # Normalize\n",
    "\n",
    "#         # Resize and preprocess the right eye image\n",
    "#         right_eye_final = cv2.resize(right_eye_roi, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "#         right_eye_final = np.expand_dims(right_eye_final, axis=0)  # Add batch dimension\n",
    "#         right_eye_final = right_eye_final / 255.0  # Normalize\n",
    "\n",
    "#         # Make the prediction for the left eye\n",
    "#         left_eye_predictions = new_model.predict(left_eye_final)\n",
    "#         left_eye_predicted_class = class_names[np.argmax(left_eye_predictions[0])]\n",
    "#         left_eye_confidence = round(100 * (np.max(left_eye_predictions[0])), 2)\n",
    "#         print(f\"Left Eye Predicted: {left_eye_predicted_class}.\\nConfidence: {left_eye_confidence}%\")\n",
    "\n",
    "#         # Make the prediction for the right eye\n",
    "#         right_eye_predictions = new_model.predict(right_eye_final)\n",
    "#         right_eye_predicted_class = class_names[np.argmax(right_eye_predictions[0])]\n",
    "#         right_eye_confidence = round(100 * (np.max(right_eye_predictions[0])), 2)\n",
    "#         print(f\"Right Eye Predicted: {right_eye_predicted_class}.\\nConfidence: {right_eye_confidence}%\")\n",
    "\n",
    "# else:\n",
    "#     print(\"No faces detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x512 1 drowsy, 74.3ms\n",
      "Speed: 3.1ms preprocess, 74.3ms inference, 79.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.3ms\n",
      "Speed: 1.6ms preprocess, 50.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.9ms\n",
      "Speed: 1.5ms preprocess, 50.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.1ms\n",
      "Speed: 1.6ms preprocess, 51.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 49.9ms\n",
      "Speed: 3.2ms preprocess, 49.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 49.4ms\n",
      "Speed: 1.7ms preprocess, 49.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.3ms\n",
      "Speed: 1.8ms preprocess, 51.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 49.8ms\n",
      "Speed: 1.6ms preprocess, 49.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 50.2ms\n",
      "Speed: 2.5ms preprocess, 50.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 49.1ms\n",
      "Speed: 2.0ms preprocess, 49.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 49.8ms\n",
      "Speed: 1.7ms preprocess, 49.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 51.3ms\n",
      "Speed: 1.8ms preprocess, 51.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 50.0ms\n",
      "Speed: 2.5ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 50.3ms\n",
      "Speed: 2.0ms preprocess, 50.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 49.8ms\n",
      "Speed: 1.6ms preprocess, 49.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 50.5ms\n",
      "Speed: 1.9ms preprocess, 50.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 51.2ms\n",
      "Speed: 2.0ms preprocess, 51.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 49.9ms\n",
      "Speed: 1.6ms preprocess, 49.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 50.7ms\n",
      "Speed: 2.6ms preprocess, 50.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 50.0ms\n",
      "Speed: 1.7ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 49.4ms\n",
      "Speed: 1.6ms preprocess, 49.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 51.8ms\n",
      "Speed: 1.5ms preprocess, 51.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 49.2ms\n",
      "Speed: 1.6ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 50.0ms\n",
      "Speed: 1.5ms preprocess, 50.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 50.9ms\n",
      "Speed: 1.6ms preprocess, 50.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 46.9ms\n",
      "Speed: 1.6ms preprocess, 46.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 50.3ms\n",
      "Speed: 1.7ms preprocess, 50.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 49.9ms\n",
      "Speed: 1.7ms preprocess, 49.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 49.7ms\n",
      "Speed: 1.7ms preprocess, 49.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.0ms\n",
      "Speed: 1.7ms preprocess, 51.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 47.0ms\n",
      "Speed: 1.5ms preprocess, 47.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 49.8ms\n",
      "Speed: 1.8ms preprocess, 49.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 49.7ms\n",
      "Speed: 2.0ms preprocess, 49.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 49.0ms\n",
      "Speed: 1.8ms preprocess, 49.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 49.9ms\n",
      "Speed: 1.6ms preprocess, 49.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.1ms\n",
      "Speed: 2.1ms preprocess, 51.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.3ms\n",
      "Speed: 1.7ms preprocess, 50.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 48.7ms\n",
      "Speed: 1.7ms preprocess, 48.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.5ms\n",
      "Speed: 1.7ms preprocess, 50.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 50.3ms\n",
      "Speed: 1.6ms preprocess, 50.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 49.6ms\n",
      "Speed: 2.0ms preprocess, 49.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 50.9ms\n",
      "Speed: 2.1ms preprocess, 50.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 51.2ms\n",
      "Speed: 1.9ms preprocess, 51.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.9ms\n",
      "Speed: 1.8ms preprocess, 51.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.9ms\n",
      "Speed: 1.7ms preprocess, 50.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 53.0ms\n",
      "Speed: 1.9ms preprocess, 53.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.8ms\n",
      "Speed: 1.7ms preprocess, 50.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.7ms\n",
      "Speed: 1.6ms preprocess, 50.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 51.2ms\n",
      "Speed: 2.0ms preprocess, 51.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 50.3ms\n",
      "Speed: 1.7ms preprocess, 50.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.7ms\n",
      "Speed: 1.8ms preprocess, 50.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 50.2ms\n",
      "Speed: 1.9ms preprocess, 50.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.2ms\n",
      "Speed: 2.0ms preprocess, 51.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.3ms\n",
      "Speed: 1.7ms preprocess, 50.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 51.4ms\n",
      "Speed: 1.6ms preprocess, 51.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.6ms\n",
      "Speed: 1.6ms preprocess, 50.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 49.6ms\n",
      "Speed: 1.6ms preprocess, 49.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.9ms\n",
      "Speed: 1.8ms preprocess, 51.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.1ms\n",
      "Speed: 1.6ms preprocess, 50.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 50.6ms\n",
      "Speed: 1.6ms preprocess, 50.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.2ms\n",
      "Speed: 1.6ms preprocess, 53.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.3ms\n",
      "Speed: 1.9ms preprocess, 51.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.2ms\n",
      "Speed: 1.9ms preprocess, 53.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.6ms\n",
      "Speed: 2.4ms preprocess, 51.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 53.2ms\n",
      "Speed: 2.1ms preprocess, 53.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "ALERT! Drowsiness detected!\n",
      "\n",
      "0: 384x512 1 drowsy, 53.2ms\n",
      "Speed: 2.2ms preprocess, 53.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 512)\n",
      "ALERT! Drowsiness detected!\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 51.5ms\n",
      "Speed: 2.7ms preprocess, 51.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "ALERT! Drowsiness detected!\n",
      "\n",
      "0: 384x512 1 drowsy, 51.8ms\n",
      "Speed: 2.0ms preprocess, 51.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "ALERT! Drowsiness detected!\n",
      "\n",
      "0: 384x512 1 awake, 53.1ms\n",
      "Speed: 2.7ms preprocess, 53.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 53.2ms\n",
      "Speed: 1.7ms preprocess, 53.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 58.6ms\n",
      "Speed: 1.9ms preprocess, 58.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 59.1ms\n",
      "Speed: 2.5ms preprocess, 59.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 60.2ms\n",
      "Speed: 1.7ms preprocess, 60.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 61.3ms\n",
      "Speed: 2.0ms preprocess, 61.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 62.1ms\n",
      "Speed: 1.8ms preprocess, 62.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 62.2ms\n",
      "Speed: 1.8ms preprocess, 62.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 62.8ms\n",
      "Speed: 1.7ms preprocess, 62.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 61.1ms\n",
      "Speed: 1.8ms preprocess, 61.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 60.0ms\n",
      "Speed: 1.5ms preprocess, 60.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 55.5ms\n",
      "Speed: 1.8ms preprocess, 55.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 54.4ms\n",
      "Speed: 1.6ms preprocess, 54.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 55.8ms\n",
      "Speed: 1.6ms preprocess, 55.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 54.5ms\n",
      "Speed: 1.7ms preprocess, 54.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 55.5ms\n",
      "Speed: 1.7ms preprocess, 55.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 54.8ms\n",
      "Speed: 2.0ms preprocess, 54.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 54.1ms\n",
      "Speed: 1.9ms preprocess, 54.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 53.5ms\n",
      "Speed: 1.7ms preprocess, 53.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 54.0ms\n",
      "Speed: 1.8ms preprocess, 54.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 54.3ms\n",
      "Speed: 1.6ms preprocess, 54.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 54.5ms\n",
      "Speed: 2.4ms preprocess, 54.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.7ms\n",
      "Speed: 1.8ms preprocess, 53.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 54.3ms\n",
      "Speed: 1.9ms preprocess, 54.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.2ms\n",
      "Speed: 1.6ms preprocess, 53.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.6ms\n",
      "Speed: 1.9ms preprocess, 52.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 54.0ms\n",
      "Speed: 1.7ms preprocess, 54.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.2ms\n",
      "Speed: 1.7ms preprocess, 52.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.3ms\n",
      "Speed: 1.6ms preprocess, 53.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.2ms\n",
      "Speed: 2.0ms preprocess, 52.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 53.8ms\n",
      "Speed: 1.6ms preprocess, 53.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.3ms\n",
      "Speed: 1.8ms preprocess, 52.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.1ms\n",
      "Speed: 1.6ms preprocess, 52.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.4ms\n",
      "Speed: 1.5ms preprocess, 53.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.5ms\n",
      "Speed: 1.5ms preprocess, 52.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.2ms\n",
      "Speed: 1.8ms preprocess, 52.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.2ms\n",
      "Speed: 1.7ms preprocess, 53.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.2ms\n",
      "Speed: 1.9ms preprocess, 51.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.2ms\n",
      "Speed: 1.9ms preprocess, 53.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "ALERT! Drowsiness detected!\n",
      "\n",
      "0: 384x512 1 drowsy, 51.3ms\n",
      "Speed: 2.0ms preprocess, 51.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "ALERT! Drowsiness detected!\n",
      "\n",
      "0: 384x512 1 drowsy, 52.7ms\n",
      "Speed: 1.6ms preprocess, 52.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "ALERT! Drowsiness detected!\n",
      "\n",
      "0: 384x512 1 drowsy, 51.0ms\n",
      "Speed: 1.8ms preprocess, 51.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "ALERT! Drowsiness detected!\n",
      "\n",
      "0: 384x512 1 drowsy, 52.7ms\n",
      "Speed: 1.8ms preprocess, 52.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "ALERT! Drowsiness detected!\n",
      "\n",
      "0: 384x512 1 drowsy, 51.4ms\n",
      "Speed: 2.0ms preprocess, 51.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "ALERT! Drowsiness detected!\n",
      "\n",
      "0: 384x512 1 drowsy, 52.7ms\n",
      "Speed: 1.6ms preprocess, 52.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "ALERT! Drowsiness detected!\n",
      "\n",
      "0: 384x512 (no detections), 52.8ms\n",
      "Speed: 1.6ms preprocess, 52.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 51.2ms\n",
      "Speed: 2.4ms preprocess, 51.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 51.8ms\n",
      "Speed: 1.7ms preprocess, 51.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.6ms\n",
      "Speed: 1.8ms preprocess, 52.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.7ms\n",
      "Speed: 1.6ms preprocess, 52.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 52.6ms\n",
      "Speed: 1.6ms preprocess, 52.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 53.9ms\n",
      "Speed: 2.0ms preprocess, 53.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 53.1ms\n",
      "Speed: 1.8ms preprocess, 53.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.6ms\n",
      "Speed: 1.6ms preprocess, 53.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.2ms\n",
      "Speed: 1.6ms preprocess, 53.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 53.9ms\n",
      "Speed: 2.2ms preprocess, 53.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.2ms\n",
      "Speed: 1.8ms preprocess, 52.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 51.9ms\n",
      "Speed: 1.9ms preprocess, 51.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.7ms\n",
      "Speed: 1.6ms preprocess, 51.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.4ms\n",
      "Speed: 2.0ms preprocess, 53.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 51.5ms\n",
      "Speed: 2.0ms preprocess, 51.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.3ms\n",
      "Speed: 1.8ms preprocess, 53.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 (no detections), 51.4ms\n",
      "Speed: 1.8ms preprocess, 51.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.1ms\n",
      "Speed: 1.6ms preprocess, 52.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.7ms\n",
      "Speed: 1.7ms preprocess, 51.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.6ms\n",
      "Speed: 1.9ms preprocess, 50.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.3ms\n",
      "Speed: 1.7ms preprocess, 51.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 52.1ms\n",
      "Speed: 1.6ms preprocess, 52.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 49.3ms\n",
      "Speed: 1.7ms preprocess, 49.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 49.7ms\n",
      "Speed: 1.6ms preprocess, 49.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 51.4ms\n",
      "Speed: 1.8ms preprocess, 51.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 49.5ms\n",
      "Speed: 2.1ms preprocess, 49.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 49.4ms\n",
      "Speed: 2.0ms preprocess, 49.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 51.2ms\n",
      "Speed: 1.8ms preprocess, 51.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 50.0ms\n",
      "Speed: 1.6ms preprocess, 50.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 49.0ms\n",
      "Speed: 2.0ms preprocess, 49.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 52.0ms\n",
      "Speed: 1.6ms preprocess, 52.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 49.3ms\n",
      "Speed: 1.7ms preprocess, 49.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 56.6ms\n",
      "Speed: 1.8ms preprocess, 56.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 56.8ms\n",
      "Speed: 1.7ms preprocess, 56.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 57.0ms\n",
      "Speed: 1.9ms preprocess, 57.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 57.0ms\n",
      "Speed: 1.7ms preprocess, 57.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 57.2ms\n",
      "Speed: 1.9ms preprocess, 57.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 57.1ms\n",
      "Speed: 1.5ms preprocess, 57.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 61.9ms\n",
      "Speed: 1.8ms preprocess, 61.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 61.0ms\n",
      "Speed: 1.8ms preprocess, 61.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 61.0ms\n",
      "Speed: 1.6ms preprocess, 61.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 56.3ms\n",
      "Speed: 1.7ms preprocess, 56.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 55.2ms\n",
      "Speed: 1.6ms preprocess, 55.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 55.9ms\n",
      "Speed: 1.9ms preprocess, 55.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 55.6ms\n",
      "Speed: 1.7ms preprocess, 55.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 55.2ms\n",
      "Speed: 1.9ms preprocess, 55.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 55.2ms\n",
      "Speed: 2.1ms preprocess, 55.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 55.3ms\n",
      "Speed: 2.3ms preprocess, 55.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 56.3ms\n",
      "Speed: 1.9ms preprocess, 56.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 53.5ms\n",
      "Speed: 1.7ms preprocess, 53.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 55.1ms\n",
      "Speed: 2.1ms preprocess, 55.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 53.9ms\n",
      "Speed: 1.8ms preprocess, 53.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 54.2ms\n",
      "Speed: 1.6ms preprocess, 54.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.9ms\n",
      "Speed: 1.6ms preprocess, 53.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 53.6ms\n",
      "Speed: 2.5ms preprocess, 53.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 54.4ms\n",
      "Speed: 1.8ms preprocess, 54.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 51.2ms\n",
      "Speed: 2.5ms preprocess, 51.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 53.2ms\n",
      "Speed: 1.6ms preprocess, 53.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 51.6ms\n",
      "Speed: 2.2ms preprocess, 51.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 53.2ms\n",
      "Speed: 1.5ms preprocess, 53.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 51.2ms\n",
      "Speed: 1.6ms preprocess, 51.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 drowsy, 50.4ms\n",
      "Speed: 1.5ms preprocess, 50.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 52.0ms\n",
      "Speed: 1.6ms preprocess, 52.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 1 drowsy, 51.8ms\n",
      "Speed: 1.9ms preprocess, 51.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "0: 384x512 1 awake, 50.9ms\n",
      "Speed: 1.6ms preprocess, 50.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 512)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import winsound\n",
    "import threading\n",
    "\n",
    "# Load YOLO model\n",
    "yolo_model = YOLO('./models/best.pt')\n",
    "\n",
    "# Load Eye Classification Model\n",
    "eye_model = tf.keras.models.load_model('models/Eye_Model1.h5')\n",
    "class_names = ['Close-Eyes', 'Open-Eyes']\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Variables for drowsiness tracking\n",
    "drowsy_start_time = None\n",
    "closed_eyes_start_time = None\n",
    "ALERT_THRESHOLD = 3  # Seconds before triggering an alert\n",
    "\n",
    "# Function to play alert sound\n",
    "def play_alert():\n",
    "    for _ in range(3):  # Beep 3 times\n",
    "        winsound.Beep(1000, 500)  # Frequency: 1000Hz, Duration: 500ms\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(img_rgb)\n",
    "\n",
    "    # Run YOLO model on the frame\n",
    "    yolo_results = yolo_model(frame)\n",
    "    frame = yolo_results[0].plot()\n",
    "\n",
    "    # Check if YOLO detects \"drowsy\"\n",
    "    yolo_drowsy_detected = any(yolo_results[0].names[int(box.cls)] == 'drowsy' for box in yolo_results[0].boxes)\n",
    "\n",
    "    # Detect eyes using MediaPipe\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            h, w, _ = frame.shape\n",
    "            left_eye_landmarks = [33, 133, 153, 154, 155, 133]\n",
    "            right_eye_landmarks = [263, 362, 387, 386, 385, 362]\n",
    "\n",
    "            # Get eye bounding boxes\n",
    "            padding = 16  # Increased padding for better eye detection\n",
    "            left_eye_x_min, left_eye_y_min = float('inf'), float('inf')\n",
    "            left_eye_x_max, left_eye_y_max = -float('inf'), -float('inf')\n",
    "            right_eye_x_min, right_eye_y_min = float('inf'), float('inf')\n",
    "            right_eye_x_max, right_eye_y_max = -float('inf'), -float('inf')\n",
    "\n",
    "            for idx in left_eye_landmarks:\n",
    "                x, y = int(face_landmarks.landmark[idx].x * w), int(face_landmarks.landmark[idx].y * h)\n",
    "                left_eye_x_min, left_eye_y_min = min(left_eye_x_min, x), min(left_eye_y_min, y)\n",
    "                left_eye_x_max, left_eye_y_max = max(left_eye_x_max, x), max(left_eye_y_max, y)\n",
    "\n",
    "            for idx in right_eye_landmarks:\n",
    "                x, y = int(face_landmarks.landmark[idx].x * w), int(face_landmarks.landmark[idx].y * h)\n",
    "                right_eye_x_min, right_eye_y_min = min(right_eye_x_min, x), min(right_eye_y_min, y)\n",
    "                right_eye_x_max, right_eye_y_max = max(right_eye_x_max, x), max(right_eye_y_max, y)\n",
    "\n",
    "            # Expand bounding box size\n",
    "            left_eye_x_min -= padding\n",
    "            left_eye_y_min -= padding\n",
    "            left_eye_x_max += padding\n",
    "            left_eye_y_max += padding\n",
    "\n",
    "            right_eye_x_min -= padding\n",
    "            right_eye_y_min -= padding\n",
    "            right_eye_x_max += padding\n",
    "            right_eye_y_max += padding\n",
    "\n",
    "            # Keep bounding boxes within frame limits\n",
    "            left_eye_x_min, left_eye_y_min = max(0, left_eye_x_min), max(0, left_eye_y_min)\n",
    "            left_eye_x_max, left_eye_y_max = min(w, left_eye_x_max), min(h, left_eye_y_max)\n",
    "            right_eye_x_min, right_eye_y_min = max(0, right_eye_x_min), max(0, right_eye_y_min)\n",
    "            right_eye_x_max, right_eye_y_max = min(w, right_eye_x_max), min(h, right_eye_y_max)\n",
    "\n",
    "            # Crop eye regions\n",
    "            left_eye_roi = frame[left_eye_y_min:left_eye_y_max, left_eye_x_min:left_eye_x_max]\n",
    "            right_eye_roi = frame[right_eye_y_min:right_eye_y_max, right_eye_x_min:right_eye_x_max]\n",
    "\n",
    "            # Resize and preprocess for prediction\n",
    "            IMAGE_SIZE = 256\n",
    "            left_eye_final = cv2.resize(left_eye_roi, (IMAGE_SIZE, IMAGE_SIZE)) / 255.0\n",
    "            right_eye_final = cv2.resize(right_eye_roi, (IMAGE_SIZE, IMAGE_SIZE)) / 255.0\n",
    "\n",
    "            left_eye_final = np.expand_dims(left_eye_final, axis=0)\n",
    "            right_eye_final = np.expand_dims(right_eye_final, axis=0)\n",
    "\n",
    "            # Predict eye status\n",
    "            left_eye_pred = class_names[np.argmax(eye_model.predict(left_eye_final))]\n",
    "            right_eye_pred = class_names[np.argmax(eye_model.predict(right_eye_final))]\n",
    "\n",
    "            # Determine eye rectangle color\n",
    "            eye_color = (0, 255, 0)  # Default: Green (Open Eyes)\n",
    "            if left_eye_pred == 'Close-Eyes' and right_eye_pred == 'Close-Eyes':\n",
    "                eye_color = (0, 0, 255)  # Red (Closed Eyes)\n",
    "\n",
    "            # Draw eye bounding boxes\n",
    "            cv2.rectangle(frame, (left_eye_x_min, left_eye_y_min), (left_eye_x_max, left_eye_y_max), eye_color, 2)\n",
    "            cv2.rectangle(frame, (right_eye_x_min, right_eye_y_min), (right_eye_x_max, right_eye_y_max), eye_color, 2)\n",
    "\n",
    "            # Start timer if eyes are closed\n",
    "            if left_eye_pred == 'Close-Eyes' and right_eye_pred == 'Close-Eyes':\n",
    "                if closed_eyes_start_time is None:\n",
    "                    closed_eyes_start_time = time.time()\n",
    "                elif time.time() - closed_eyes_start_time >= ALERT_THRESHOLD:\n",
    "                    print(\"ALERT! Eyes closed for too long!\")\n",
    "                    threading.Thread(target=play_alert).start()\n",
    "            else:\n",
    "                closed_eyes_start_time = None  # Reset timer\n",
    "\n",
    "    # Start timer if YOLO detects drowsiness\n",
    "    if yolo_drowsy_detected:\n",
    "        if drowsy_start_time is None:\n",
    "            drowsy_start_time = time.time()\n",
    "        elif time.time() - drowsy_start_time >= ALERT_THRESHOLD:\n",
    "            print(\"ALERT! Drowsiness detected!\")\n",
    "            threading.Thread(target=play_alert).start()\n",
    "    else:\n",
    "        drowsy_start_time = None  # Reset timer\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Real-Time Drowsiness Detection\", frame)\n",
    "\n",
    "    # Exit on 'Esc' key\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
